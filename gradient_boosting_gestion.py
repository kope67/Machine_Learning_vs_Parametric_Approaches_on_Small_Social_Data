import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# === 1. Lecture du fichier CSV ===
csv_path = "data/simplifier_caractÃ©ristique numÃ©rique_gestionnaires.csv"  # ğŸ” adapte ce chemin
feature_cols = ["13.exp_pro", "15. Taille_Ã©quipe"]  # ğŸ” colonnes d'entrÃ©e
target_col = "formation_complement"                # ğŸ” colonne de sortie

#df = pd.read_csv(csv_path)
df = pd.read_csv(csv_path, sep=";", engine="python", encoding="utf-8")

# SÃ©parer X et y
X = df[feature_cols]
y = df[target_col]

# === 2. ModÃ¨le Gradient Boosting ===
gb = GradientBoostingClassifier(
    n_estimators=100,     # Nombre dâ€™arbres faibles
    learning_rate=0.1,    # Taux dâ€™apprentissage
    max_depth=3,          # Profondeur max des arbres
    subsample=1.0,        # <1.0 pour stochastic gradient boosting
    random_state=42
)

# EntraÃ®nement
gb.fit(X, y)

# PrÃ©diction
y_pred = gb.predict(X)

# RÃ©sultat
print("Accuracy Boosting:", accuracy_score(y, y_pred))

# === 3. Visualiser l'Ã©volution du loss ===
plt.plot(gb.train_score_)
plt.title("Ã‰volution du loss Ã  chaque itÃ©ration")
plt.xlabel("Nombre dâ€™arbres")
plt.ylabel("DÃ©viance (log-loss)")
plt.grid()
plt.show()